{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d1b7d9",
   "metadata": {},
   "source": [
    "Hello everyone,\n",
    "\n",
    "In this module, it is required to implement the preprocessor for Arabic Font Identification System.\n",
    "\n",
    "At first, what are the main steps that we should go through in this module?\n",
    "\n",
    "\n",
    "# TODOs:\n",
    "\n",
    "1. Understand the problem\n",
    "2. Binarization\n",
    "3. Extract Edges\n",
    "4. Extract Skeleton\n",
    "5. Extract Diacritics\n",
    "6. Extract Text only\n",
    "7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9deb665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### imports #####################################################\n",
    "from skimage.morphology import skeletonize\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "from skimage.segmentation import flood_fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbcf51",
   "metadata": {},
   "source": [
    "# 1. Understand the problem\n",
    "\n",
    "We are interested only in the morphology of text letters, all images are first converted into binary (i.e., black text on a white background). It should be known that most images contain either meaningful texture, which is a part of the decoration or a meaningless one that resulted from the noise while capturing. In either case, we illuminate the background so it does not affect the results.\n",
    "\n",
    "- Input: --\n",
    "- Output: --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d6a89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_histogram(binary, show_hist=False):\n",
    "\n",
    "    \"\"\"Gets a binary image and returns it reverted if text was black (Makes text white for all images)\n",
    "        Except for Square Kuffi\n",
    "\n",
    "    Args:\n",
    "        binary : The binary image you want to transform for consistency (White text on black bg) (Read using cv2)\n",
    "        \n",
    "    Returns:\n",
    "        binary || reverted_binary : The outcome of analysis (Binary image with white text on black bg)\n",
    "    \"\"\"\n",
    "\n",
    "    height = (binary.shape)[0]\n",
    "    white_pixels_in_row = []\n",
    "    \n",
    "    # Calculate number of white pixels in a row\n",
    "    for row in range(height - 1):\n",
    "        white_pixels_in_row.append((binary[row, :] == 1).sum())\n",
    "\n",
    "    # Set the threshold of white pixels in a row to be 70% of the row with most white pixels\n",
    "    # We use this threshold to see how many rows contain a high number of white pixels \n",
    "    pixels_threshold = int(0.7 * max(white_pixels_in_row))\n",
    "\n",
    "    # Get the number of rows above the pixels_threshold\n",
    "    rows_above_thresh = 0\n",
    "    for row_pixels in white_pixels_in_row:\n",
    "        if row_pixels > pixels_threshold:\n",
    "            rows_above_thresh += 1\n",
    "\n",
    "    # Calculate the ratio between the number of rows dominated by white pixels to the number of rows in the entire image\n",
    "    ratio = rows_above_thresh / height\n",
    "\n",
    "    # if show_hist:\n",
    "    #     x = np.arange(height)\n",
    "    #     plt.figure(figsize =(10, 7)) \n",
    "    #     plt.plot(x, white_pixels_in_row)\n",
    "    #     plt.show()\n",
    "    \n",
    "    # If more than 70% of the image is white rows then the background is white and we have to revert the image\n",
    "    if ratio > 0.7:\n",
    "        return 1 - binary\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb1f9a",
   "metadata": {},
   "source": [
    "# 2. Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c22183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(image):\n",
    "    \"\"\"Gets an image and returns it binarized having values 0 OR 1 using OTSU thresholding technique\n",
    "\n",
    "    Args:\n",
    "        image : The image you want to binarize (Read using cv2)\n",
    "        \n",
    "    Returns:\n",
    "        binarized: The binarized version of the image\n",
    "    \"\"\"\n",
    "    # Use Otsu for normal binarization\n",
    "    # The parameters are 1-`The input image`, 2-`The binarization threshold (will not be used if OTSU technique is used)`,\n",
    "    #                        3-`Maximum value`, 4-`Binarization technique`\n",
    "    th, binary_image = cv2.threshold(image, 128, 1, cv2.THRESH_OTSU)\n",
    "\n",
    "    # Perform histogram analysis to make text white for all images (Except for square Kuffi)\n",
    "    corrected_binary_image = analyze_histogram(binary_image)\n",
    "    return corrected_binary_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fac6469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img):\n",
    "    morph_img = img\n",
    "\n",
    "    rows = morph_img.sum(axis=1)\n",
    "    cols = morph_img.sum(axis=0)\n",
    "    rows = rows != 0\n",
    "    cols = cols != 0\n",
    "\n",
    "    c = np.where(cols == cols.max())[0]\n",
    "    r = np.where(rows == rows.max())[0]\n",
    "\n",
    "    x = c[0], c[-1]\n",
    "    y = r[0], r[-1]\n",
    "    \n",
    "    try:\n",
    "        cropped_img = img[y[0]:y[1], x[0]:x[1]]\n",
    "    except:\n",
    "        cropped_img = img\n",
    "\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a899840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_CUBIC):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # if h <= height:\n",
    "            # return image\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        t = int(height / h)\n",
    "        x = int(h / height)\n",
    "        if x == 0:\n",
    "            height = int(h*t)\n",
    "        else:\n",
    "            height = int(h/x)\n",
    "        if h > height: #shrink\n",
    "            inter = cv2.INTER_AREA\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # if w <= width:\n",
    "            # return image\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        t = int(width / w)\n",
    "        width = t * w\n",
    "        x = int(w / width)\n",
    "        if x == 0:\n",
    "            width = int(w*t)\n",
    "        else:\n",
    "            width = int(w/x)\n",
    "\n",
    "        if w > width: #shrink\n",
    "            inter = cv2.INTER_AREA\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d913b8",
   "metadata": {},
   "source": [
    "# 3. Extract Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b54b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edges(image):\n",
    "    \"\"\"Gets the original input image and returns an image containing its edges using canny edge detector\n",
    "\n",
    "    Args:\n",
    "        image: The image you want to extract its edges (Read using cv2)\n",
    "        \n",
    "    Returns:\n",
    "        edge_image: The edge extracted image\n",
    "    \"\"\"\n",
    "    # Blur the image for better edge detection\n",
    "    if image.max() == 1:\n",
    "        image = image * 255\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "    img_blur = cv2.GaussianBlur(image,(3,3), sigmaX=0, sigmaY=0)\n",
    "\n",
    "    # Use Canny edge detection to extract edges\n",
    "    edge_image = cv2.Canny(image=img_blur, threshold1=100, threshold2=200)\n",
    "\n",
    "    # Change image max value from 255 to 1\n",
    "    edge_image[edge_image == 255] = 1\n",
    "\n",
    "    return edge_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96ee17",
   "metadata": {},
   "source": [
    "# 4. Extract Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820257d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skeleton(image):\n",
    "    \"\"\"Gets an image and returns an image containing its skeleton \n",
    "\n",
    "    Args:\n",
    "        image: The image you want to skeletonize (Read using cv2)\n",
    "        \n",
    "    Returns:\n",
    "        skeleton: The skeletonized image\n",
    "    \"\"\"\n",
    "    # Use Skimage's skeletonize method with the array representation of the binary image as input\n",
    "    skeleton = skeletonize(np.asarray(image)).astype(np.uint8)\n",
    "\n",
    "    return skeleton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1548d45c",
   "metadata": {},
   "source": [
    "# 5. Separate Diacritics from Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c26a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_diacritics_and_text_utility(image):\n",
    "    \"\"\"Utility function used by separate_diacritics_and_text\n",
    "    \"\"\"\n",
    "    \n",
    "    # binary = binarize(image)  \n",
    "    binary = image  \n",
    "\n",
    "    # height = (binary.shape)[0]\n",
    "    # white_pixels_in_row = np.zeros(height, dtype=np.uint32)  \n",
    "    # Calculate number of white pixels in a row\n",
    "    # for row in range(height - 1):\n",
    "        # white_pixels_in_row[row] = (binary[row, :] == 1).sum()\n",
    "\n",
    "    white_pixels_in_row = binary.sum(axis=1)\n",
    "\n",
    "    # Get the row with most white pixels (This row would contain only text and commas no diacritics\n",
    "    #                                        as it is an imaginary line where text is placed on)\n",
    "    baseline_row = np.argmax(white_pixels_in_row)\n",
    "    diacritics_image = binary\n",
    "\n",
    "    # How Flood Fill works for our case:\n",
    "    #   It starts at a seed point (pixel) and changes all connected pixels to it to have a certain color\n",
    "    #   So what we want to do is get the first pixel of each word along the line (it would be black) and  \n",
    "    #   use that point as seed for the flood_fill algorithm changing that word to have the same color as\n",
    "    #   the background. We keep doing that for all words until only diacritics remain.\n",
    "\n",
    "    # Loop through the base_line's pixels to apply flood fill on all words\n",
    "    rowPixels = binary[baseline_row, :]\n",
    "    for i in range(len(rowPixels) - 1):\n",
    "        # Handle the case where the first pixel is part of a word so we apply the flood fill from the end of the word\n",
    "        if rowPixels[i] == 1 and rowPixels[i+1] == 0:\n",
    "            diacritics_image = flood_fill(diacritics_image, (baseline_row, i), 0)\n",
    "        elif rowPixels[i] == 0 and rowPixels[i+1] == 1:\n",
    "            diacritics_image = flood_fill(diacritics_image, (baseline_row, i+1), 0)\n",
    "    \n",
    "    # print(baseline_row, binary.shape[0])\n",
    "    text_image = binary - diacritics_image\n",
    "    cv2.line(text_image,(0,baseline_row),(image.shape[1],baseline_row),(0,0,255),2)\n",
    "    \n",
    "    return diacritics_image, text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26cb2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_diacritics_and_text(image, diacritics_ratio=0.2, max_iterations=10, text_convergence_threshold=5):\n",
    "    \"\"\"Gets an input image of the arabic text and returns an image containing only the diacritics in it and another\n",
    "    image with the text as a tuple (diacritics, text)\n",
    "        \n",
    "    Args:\n",
    "        image: The image you want to separate its diacritics from its text (Read using cv2)\n",
    "        diacritics_ratio: threshold ratio of diacritics to text (default 0.2)\n",
    "        max_iterations: maximum number of iterations to run the separtion algorithm (default 1000)\n",
    "    Returns:\n",
    "        diacritics_image: A binary image containing only diacritics (white text on black bg)\n",
    "        text_image: A binary image containing only text (white text on black bg)\n",
    "    \"\"\"\n",
    "\n",
    "    diacritics_image, text_image = separate_diacritics_and_text_utility(image)\n",
    "    # while diacritics_image.sum() > diacritics_image.size * diacritics_ratio:\n",
    "    while diacritics_image.sum() > text_image.sum() * diacritics_ratio and max_iterations:\n",
    "        diacritics_image, text_image_1 = separate_diacritics_and_text_utility(diacritics_image)\n",
    "        if text_image_1.sum() < text_convergence_threshold:\n",
    "            break\n",
    "        text_image = text_image + text_image_1\n",
    "        max_iterations = max_iterations - 1\n",
    "        \n",
    "    return diacritics_image, text_image\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b977652",
   "metadata": {},
   "source": [
    "# 6. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346b6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing():\n",
    "    \n",
    "    # importing io module\n",
    "    import sys\n",
    "    sys.path.insert(1, \"./../io_utils/\")\n",
    "    from io_utils import read_data, read_classes\n",
    "\n",
    "    # reading data and class names\n",
    "    classes_names = read_classes('../ACdata_base/names.txt')\n",
    "    dataset_images, dataset_labels = read_data('../ACdata_base/')\n",
    "    \n",
    "    assert len(dataset_images) == len(dataset_labels)\n",
    "\n",
    "    # get the range of each class in the dataset\n",
    "    ranges = [0]\n",
    "    tmp = dataset_labels[0]\n",
    "    for idx, num in enumerate(dataset_labels):\n",
    "        if num != tmp:\n",
    "            tmp = num\n",
    "            ranges.append(idx)\n",
    "    ranges.append(len(dataset_labels))\n",
    "\n",
    "    # plt.imshow(crop(binarize(cv2.imread(\"../ACdata_base/9/1624.jpg\", 0))), cmap='gray')\n",
    "\n",
    "    # Choosing a random example from each class and apply the preprocessing Functions on it\n",
    "    for i, class_name in enumerate(classes_names):\n",
    "        index = randrange(ranges[i], ranges[i+1])\n",
    "        test_image = dataset_images[index]\n",
    "\n",
    "        if(i == 8):\n",
    "            test_image = cv2.imread(\"../ACdata_base/9/1624.jpg\", 0)\n",
    "\n",
    "        binary_image = binarize(test_image)\n",
    "        cropped_image = crop(binary_image)\n",
    "        assert len(np.unique(np.asarray(binary_image))) == 2\n",
    "\n",
    "        edge_image = extract_edges(cropped_image)\n",
    "        skeleton_image = extract_skeleton(cropped_image)\n",
    "        diacritics_image, text_image = separate_diacritics_and_text(cropped_image)\n",
    "\n",
    "        f, axarr = plt.subplots(3,2, figsize=(15, 10))\n",
    "        f.suptitle(class_name + \" test\")\n",
    "\n",
    "        axarr[0,0].imshow(test_image, cmap='gray')\n",
    "        axarr[0,0].set_title(\"Original\")\n",
    "\n",
    "        # axarr[0,1].imshow(binary_image, cmap='gray')\n",
    "        # axarr[0,1].set_title(\"Binary\")\n",
    "        axarr[0,1].imshow(cropped_image, cmap='gray')\n",
    "        axarr[0,1].set_title(\"Cropped Binary\")\n",
    "\n",
    "        axarr[1,0].imshow(edge_image, cmap='gray')\n",
    "        axarr[1,0].set_title(\"Edge\")\n",
    "\n",
    "        axarr[1,1].imshow(skeleton_image, cmap='gray')\n",
    "        axarr[1,1].set_title(\"Skeleton\")\n",
    "\n",
    "        axarr[2,0].imshow(diacritics_image, cmap='gray')\n",
    "        axarr[2,0].set_title(\"Diacritics\")\n",
    "\n",
    "        axarr[2,1].imshow(text_image, cmap='gray')\n",
    "        axarr[2,1].set_title(\"Text Only\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766aa718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "    # testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103343e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_py():\n",
    "    !jupyter nbconvert --to script preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b9bff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook preprocessing.ipynb to script\n",
      "[NbConvertApp] Writing 12484 bytes to preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    create_py()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
